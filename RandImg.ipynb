{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54207aac-3e11-4238-a84e-47cf39931e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 random images generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Directory where images will be saved\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to generate random image\n",
    "def generate_random_image(width, height, image_number):\n",
    "    image = Image.new('RGB', (width, height))\n",
    "    pixels = image.load()\n",
    "\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            # Random RGB color for each pixel\n",
    "            pixels[i, j] = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "    # Save the image\n",
    "    image.save(f\"{output_dir}/random_image_{image_number}.png\")\n",
    "\n",
    "# Generate 100 random images with specified dimensions\n",
    "for i in range(1, 1001):\n",
    "    generate_random_image(256, 256, i)\n",
    "\n",
    "print(\"1000 random images generated successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fed81c5-1eb2-4f49-b745-865f6503a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef664a4-9f1a-41d5-b8f9-b4fdcf46f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')\n",
    "if os.path.isdir('train/positive') is False:\n",
    "    os.makedirs( 'train/positive')\n",
    "    os.makedirs('train/negative')\n",
    "    os.makedirs('train/neutral')\n",
    "    os.makedirs( 'valid/positive')\n",
    "    os.makedirs('valid/negative')\n",
    "    os.makedirs( 'valid/neutral')\n",
    "    os.makedirs ('test/positive')\n",
    "    os.makedirs( 'test/negative')\n",
    "    os.makedirs ('test/neutral')\n",
    "for c in random.sample(glob.glob( 'random_image*'), 233):\n",
    "    shutil.move(c, 'train/positive' )\n",
    "for c in random.sample(glob.glob( 'random_image*'), 233):\n",
    "    shutil.move(c, 'train/negative' )\n",
    "for c in random.sample(glob.glob( 'random_image*'), 233):\n",
    "    shutil.move(c, 'train/neutral' )\n",
    "for c in random.sample(glob.glob( 'random_image*'), 66):\n",
    "    shutil.move(c, 'valid/positive' )\n",
    "for c in random.sample(glob.glob( 'random_image*'), 66):\n",
    "    shutil.move(c, 'valid/negative' )\n",
    "for c in random.sample(glob.glob( 'random_image*'), 66):\n",
    "    shutil.move(c, 'valid/neutral' )\n",
    "for c in random.sample(glob.glob( 'random_image*'), 33):\n",
    "    shutil.move(c, 'test/positive' )\n",
    "for c in random.sample(glob.glob( 'random_image*'), 33):\n",
    "    shutil.move(c, 'test/negative' )\n",
    "for c in random.sample(glob.glob( 'random_image*'), 33):\n",
    "    shutil.move(c, 'test/neutral' )\n",
    "    \n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def6eab8-15f1-4843-a07e-4ba8d878a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path(\"data/train\")\n",
    "valid_path = Path(\"data/valid\")\n",
    "test_path = Path(\"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c55d9299-121f-4d68-a8c2-3a4dc8852270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.1099\n",
      "Validation Accuracy: 0.3333\n",
      "Epoch 2/10, Loss: 1.1011\n",
      "Validation Accuracy: 0.3333\n",
      "Epoch 3/10, Loss: 1.1004\n",
      "Validation Accuracy: 0.3333\n",
      "Epoch 4/10, Loss: 1.1018\n",
      "Validation Accuracy: 0.3333\n",
      "Epoch 5/10, Loss: 1.0999\n",
      "Validation Accuracy: 0.3333\n",
      "Epoch 6/10, Loss: 1.0988\n",
      "Validation Accuracy: 0.3333\n",
      "Epoch 7/10, Loss: 1.0983\n",
      "Validation Accuracy: 0.3333\n",
      "Epoch 8/10, Loss: 1.0989\n",
      "Validation Accuracy: 0.3384\n",
      "Epoch 9/10, Loss: 1.0990\n",
      "Validation Accuracy: 0.3333\n",
      "Epoch 10/10, Loss: 1.0968\n",
      "Validation Accuracy: 0.3687\n",
      "Test Accuracy: 0.3232\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define paths and parameters\n",
    "data_path = Path(\"data\")  # Update this path to your dataset location\n",
    "batch_size = 16\n",
    "num_classes = 3  # Number of sentiment classes (e.g., positive, negative, neutral)\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to match the input size of ViT\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ViT normalization\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = ImageFolder(root=f'{data_path}/training', transform=transform)\n",
    "valid_dataset = ImageFolder(root=f'{data_path}/validation', transform=transform)\n",
    "test_dataset = ImageFolder(root=f'{data_path}/testing', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the Vision Transformer model\n",
    "model_name = 'google/vit-base-patch16-224-in21k'\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model, train_loader, valid_loader, test_loader, num_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).logits\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # Test\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Run training and evaluation\n",
    "train_and_evaluate(model, train_loader, valid_loader, test_loader, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39114b-1d89-42c4-8e79-4f7aa0167972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
